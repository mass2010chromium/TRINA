{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "trina_dir = os.path.join(home,'TRINA')\n",
    "os.chdir(trina_dir)\n",
    "\n",
    "from Jarvis import Jarvis\n",
    "from SensorModule import Camera_Robot\n",
    "from Motion import MotionClient\n",
    "from klampt import WorldModel,Geometry3D\n",
    "robot_ip =  'http://localhost:8080'\n",
    "mode = 'Kinematic'\n",
    "components = ['base','left_limb','right_limb','left_gripper']\n",
    "robot = MotionClient(address = robot_ip)\n",
    "robot.restartServer(mode = mode, components = components,codename = 'anthrax_lowpoly')\n",
    "world_file = './Motion/data/TRINA_world_anthrax_PointClick.xml'\n",
    "world = WorldModel()\n",
    "world.readFile(world_file )\n",
    "sensor_module = Camera_Robot(robot = robot,world = world, ros_active = False)\n",
    "jarvis = Jarvis(str('devel'),sensor_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     26
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip2 install pandas\n",
    "import pandas as pd\n",
    "import redis\n",
    "from reem.connection import RedisInterface\n",
    "from reem.datatypes import KeyValueStore\n",
    "import time\n",
    "from threading import Thread,Lock\n",
    "from copy import deepcopy,copy\n",
    "import h5py \n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import atexit\n",
    "\n",
    "class TrinaQueueReader(object):\n",
    "    def __init__(self, host = 'localhost', port = 6379):\n",
    "        self.r = redis.Redis(host = host, port = port)\n",
    "    def read(self,key):\n",
    "        with self.r.pipeline() as pipe:\n",
    "            times = self.r.llen(key)\n",
    "            for i in range(times):\n",
    "                pipe.lpop(key)\n",
    "            res = pipe.execute()\n",
    "        return res\n",
    "    \n",
    "class StateLogger(object):\n",
    "    def __init__(self, jarvis, frequency=60, image_frequency=10):\n",
    "        print('\\n\\n\\n starting logger \\n\\n\\n')\n",
    "\n",
    "        self.states_lock = Lock()\n",
    "        self.commands_lock = Lock()\n",
    "        self.images_lock = Lock()\n",
    "        self.dt = 1.0/frequency\n",
    "        self.images_dt = 1.0/image_frequency\n",
    "        self.command_reader = TrinaQueueReader()\n",
    "\n",
    "        self.intermediate_wait = 5\n",
    "        tmp = datetime.now()\n",
    "        if(not os.path.exists('./logs')):\n",
    "            os.mkdir('./logs')\n",
    "        self.name = tmp.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        jarvis.server['LOGGER_NAME'] = self.name\n",
    "        self.start_all_logger_variables()\n",
    "        atexit.register(self.safely_close)\n",
    "        \n",
    "        \n",
    "        self.stateThread = Thread(target=self.update_states)\n",
    "        self.commandThread = Thread(target=self.update_command_logs)\n",
    "        self.saveStateLogThread = Thread(\n",
    "            target=self.save_state_and_command_log)\n",
    "        self.updateImageThread = Thread(target=self.update_images)\n",
    "        self.saveImageLog = Thread(target=self.save_images_to_disk)\n",
    "        self.stateThread.daemon = False\n",
    "        self.commandThread.daemon = False\n",
    "        self.saveStateLogThread.daemon = False\n",
    "        self.updateImageThread.daemon = False\n",
    "        self.saveImageLog.daemon = False\n",
    "        self.stateThread.start()\n",
    "        self.commandThread.start()\n",
    "        self.updateImageThread.start()\n",
    "        time.sleep(3)\n",
    "        self.saveStateLogThread.start()\n",
    "        self.saveImageLog.start()\n",
    "    \n",
    "    def start_all_logger_variables(self):\n",
    "        with self.states_lock:\n",
    "            with self.commands_lock:\n",
    "                with self.images_lock:\n",
    "                    self.status_filename = \"./logs/\"+self.name + \".gz\"\n",
    "                    self.images_filename = \"./logs/\"+self.name +\".hdf5\"\n",
    "                    self.images = {}\n",
    "                    self.image_times = {}\n",
    "                    self.command_list = []\n",
    "                    self.ui_state = []\n",
    "                    self.robot_state = []\n",
    "                    self.jarvis = jarvis\n",
    "                    self.ui_times = []\n",
    "                    self.robot_state_times = []\n",
    "                    tmp = self.jarvis.get_rgbd_images()\n",
    "                    tmp = self.jarvis.get_rgbd_images()\n",
    "                    keys = tmp.keys()\n",
    "                    self.close_all = False\n",
    "                    # we start the key dictionaries\n",
    "                    for key in keys:\n",
    "                        self.images.update({key+'_color': [], key+'_depth': []})\n",
    "                        self.image_times.update({key+'_color': [], key+'_depth': []})\n",
    "\n",
    "                    for key in keys:\n",
    "                        self.images[key+'_color'].append(tmp[key][0])\n",
    "                        self.images[key+'_depth'].append(tmp[key][1])\n",
    "                        self.image_times[key+'_color'].append(tmp[key][2])\n",
    "                        self.image_times[key+'_depth'].append(tmp[key][2])\n",
    "#                         print('this is the first time!')\n",
    "#                         print(tmp[key][2])\n",
    "                    # we also start the datasets:\n",
    "                    self.f = h5py.File(self.images_filename, 'w')\n",
    "                    for dataset_name in tmp.keys():\n",
    "                        size = tmp[dataset_name][0].shape\n",
    "                        self.f.create_dataset(dataset_name + '_color', (1, size[0], size[1], size[2]), chunks=True, maxshape=(\n",
    "                            None, size[0], size[1], size[2]), compression='gzip', dtype='uint8')\n",
    "                        self.f[dataset_name + '_color'].attrs.create('times',self.image_times[dataset_name + '_color'])\n",
    "\n",
    "                    #then for depth\n",
    "                    for dataset_name in tmp.keys():\n",
    "                        size = tmp[dataset_name][1].shape\n",
    "                        self.f.create_dataset(dataset_name + '_depth', (1, size[0], size[1]), chunks=True, maxshape=(\n",
    "                            None, size[0], size[1]), compression='gzip')\n",
    "                        self.f[dataset_name + '_depth'].attrs.create('times',self.image_times[dataset_name + '_depth'])\n",
    "\n",
    "                    self.datasets = {}\n",
    "\n",
    "                    for name in self.f.keys():\n",
    "                        self.datasets.update({name: self.f[name]})\n",
    "\n",
    "    def update_states(self):\n",
    "        while(True):\n",
    "            start = time.time()\n",
    "            new_name = self.jarvis.server['LOGGER_NAME'].read()\n",
    "            if(new_name != self.name):\n",
    "                self.name = new_name\n",
    "                self.start_all_logger_variables()\n",
    "            with self.states_lock:\n",
    "                self.ui_state.append(str(self.jarvis.getUIState()))\n",
    "                self.ui_times.append(str(self.jarvis.getTrinaTime()))\n",
    "                self.robot_state.append(str(self.jarvis.getRobotState()))\n",
    "                self.robot_state_times.append(str(self.jarvis.getTrinaTime()))\n",
    "\n",
    "            elapsed = time.time()-start\n",
    "            if(elapsed < self.dt):\n",
    "                time.sleep(self.dt-elapsed)\n",
    "            if(self.close_all):\n",
    "                break\n",
    "\n",
    "    def update_command_logs(self):\n",
    "        while(True):\n",
    "            start = time.time()\n",
    "            with self.commands_lock:\n",
    "                new_commands = self.command_reader.read('EXECUTED_COMMANDS')\n",
    "                if(new_commands):\n",
    "                    try:\n",
    "                        if(new_commands[0]):\n",
    "                            self.command_list.append(new_commands)\n",
    "                    except:\n",
    "                        print('error')\n",
    "            elapsed = time.time()-start\n",
    "            if(elapsed < self.dt):\n",
    "                time.sleep(self.dt-elapsed)\n",
    "            if(self.close_all):\n",
    "                break\n",
    "\n",
    "    def yield_states_df(self):\n",
    "        with self.states_lock:\n",
    "            copy_ui_state = copy(self.ui_state)\n",
    "            copy_robot_state = copy(self.robot_state)\n",
    "            copy_ui_times = copy(self.ui_times)\n",
    "            copy_robot_state_times = copy(self.robot_state_times)\n",
    "            self.ui_state = []\n",
    "            self.robot_state = []\n",
    "            self.ui_times = []\n",
    "            self.robot_state_times = []\n",
    "        nature_ui = len(copy_ui_state)*['ui']\n",
    "        nature_robot = len(copy_robot_state)*['robot']\n",
    "        logs = copy_ui_state + copy_robot_state\n",
    "        times = copy_ui_times + copy_robot_state_times\n",
    "        natures = nature_ui + nature_robot\n",
    "        states_df = pd.DataFrame(\n",
    "            {'log': logs, 'trina_time': times, 'nature': natures})\n",
    "\n",
    "        return states_df\n",
    "\n",
    "    def yield_commands_df(self):\n",
    "        with self.commands_lock:\n",
    "            copy_command_list = copy(self.command_list)\n",
    "            self.command_list = []\n",
    "\n",
    "        commands = []\n",
    "        command_times = []\n",
    "        for i in copy_command_list:\n",
    "            exec('tmp = {}'.format(i))\n",
    "            for j in tmp:\n",
    "                exec('tmp2 = {}'.format(j))\n",
    "                commands.append(tmp2[0])\n",
    "                command_times.append(tmp2[1])\n",
    "\n",
    "        if(commands):\n",
    "            commands_df = pd.DataFrame(\n",
    "                {'log': commands, 'trina_time': command_times})\n",
    "\n",
    "            commands_df['nature'] = 'command'\n",
    "\n",
    "            commands_df.columns = ['log', 'trina_time', 'nature']\n",
    "        else:\n",
    "            commands_df = pd.DataFrame(\n",
    "                {'log': [], 'trina_time': [], 'nature': []})\n",
    "        return commands_df\n",
    "\n",
    "    def update_images(self):\n",
    "        while(True):\n",
    "            start = time.time()\n",
    "            with self.images_lock:\n",
    "                tmp = self.jarvis.get_rgbd_images()\n",
    "                for key in tmp.keys():\n",
    "                    self.images[key+'_color'].append(tmp[key][0])\n",
    "                    self.images[key+'_depth'].append(tmp[key][1])\n",
    "                    self.image_times[key+'_color'].append(tmp[key][2])\n",
    "                    self.image_times[key+'_depth'].append(tmp[key][2])\n",
    "            elapsed = time.time()-start\n",
    "            if(elapsed < self.images_dt):\n",
    "                time.sleep(self.images_dt-elapsed)\n",
    "            if(self.close_all):\n",
    "                break\n",
    "\n",
    "    def save_state_and_command_log(self):\n",
    "\n",
    "        while(True):\n",
    "\n",
    "            start_time = time.time()\n",
    "            commands_df = self.yield_commands_df()\n",
    "            states_df = self.yield_states_df()\n",
    "            final_df = commands_df.append(\n",
    "                states_df, ignore_index=True, sort=False)\n",
    "            final_df.trina_time = final_df.trina_time.astype(float)\n",
    "            final_df = final_df.sort_values(\n",
    "                by='trina_time').drop_duplicates().reset_index(drop=True)\n",
    "            final_df = final_df.astype(str)\n",
    "            if(os.path.exists(self.status_filename)):\n",
    "                final_df.to_csv(self.status_filename, sep='|',\n",
    "                                mode='a', header=False, index=False)\n",
    "            else:\n",
    "                final_df.to_csv(self.status_filename, sep='|',\n",
    "                                mode='a', header=True, index=False)\n",
    "\n",
    "            elapsed = time.time()-start_time\n",
    "            if(elapsed < self.intermediate_wait):\n",
    "                time.sleep(self.intermediate_wait-elapsed)\n",
    "            if(self.close_all):\n",
    "                break\n",
    "\n",
    "    def save_images_to_disk(self):\n",
    "        while(True):\n",
    "            start_time = time.time()\n",
    "            with self.images_lock:\n",
    "                copy_images = copy(self.images)\n",
    "                copy_image_times = copy(self.image_times)\n",
    "                for key in self.images.keys():\n",
    "                    self.images.update({key: []})\n",
    "                    self.image_times.update({key:[]})\n",
    "            for key in copy_images.keys():\n",
    "                dset = self.datasets[key]\n",
    "                dset_size = list(dset.shape)\n",
    "                new_data_array = np.array(copy_images[key])\n",
    "                new_dset_size = copy(dset_size)\n",
    "                new_dset_size[0] += new_data_array.shape[0]\n",
    "                new_dset_size = tuple(new_dset_size)\n",
    "                dset.resize(new_dset_size)\n",
    "                dset[dset_size[0]:dset_size[0] +\n",
    "                     new_data_array.shape[0], :, :] = new_data_array\n",
    "                old_times = dset.attrs.get('times')\n",
    "                new_times = np.append(old_times,np.array(copy_image_times[key]))\n",
    "                print(new_dset_size)\n",
    "                dset.attrs.create('times',new_times)\n",
    "            self.f.flush()\n",
    "            elapsed = time.time()-start_time\n",
    "            if(elapsed < self.intermediate_wait):\n",
    "                time.sleep(self.intermediate_wait-elapsed)\n",
    "            if(self.close_all):\n",
    "                break\n",
    "\n",
    "    def safely_close(self):\n",
    "        print('safely closing hdf5 files')\n",
    "        self.close_all = True\n",
    "        time.sleep(5)\n",
    "        self.f.flush()\n",
    "        self.f.close()\n",
    "\n",
    "    def return_threads(self):\n",
    "\t    return [self.stateThread, self.commandThread, self.saveStateLogThread, self.updateImageThread, self.saveImageLog]\n",
    "    \n",
    "    def return_processes(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_logger = StateLogger(jarvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_logger.safely_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd\n",
    "\n",
    "s = glob.glob('./logs/*')\n",
    "a = pd.read_csv(s[0], sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "tmp = jarvis.get_rgbd_images()\n",
    "keys = tmp.keys()\n",
    "for key in keys:\n",
    "    images.update({key+'_color':[],key+'_depth':[]})\n",
    "for i in range(100):\n",
    "    tmp = jarvis.get_rgbd_images()\n",
    "\n",
    "    for key in keys:\n",
    "        images[key+'_color'].append(tmp[key][0])\n",
    "        images[key+'_depth'].append(tmp[key][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = images.keys()\n",
    "a = k[0]\n",
    "s = np.array(images[a])\n",
    "\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import glob \n",
    "import os\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "trina_dir = os.path.join(home,'TRINA')\n",
    "os.chdir(trina_dir)\n",
    "\n",
    "\n",
    "s = glob.glob('./logs/*.hdf5')\n",
    "f = h5py.File(s[7],'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f[f.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dset.attrs.get('times')\n",
    "import numpy as np\n",
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "times = np.random.rand(dset.shape[0]).tolist()\n",
    "dset.attrs.create('times',times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.attrs.get('times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jarvis.get_rgbd_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then create h5py datasets:\n",
    "# first for color:\n",
    "for dataset_name in a.keys():\n",
    "    size = a[dataset_name][0].shape\n",
    "    f.create_dataset(dataset_name + '_color',(1,size[0],size[1]), chunks=True,maxshape = (None,size[0],size[1]),compression = 'gzip')\n",
    "    \n",
    "#then for depth\n",
    "for dataset_name in a.keys():\n",
    "    size = a[dataset_name][0].shape\n",
    "    f.create_dataset(dataset_name + '_depth',(1,size[0],size[1]), chunks=True,maxshape = (None,size[0],size[1]),compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for key in f.keys():\n",
    "    datasets.update({key:f[key]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[f.keys()[0]].resize((100,480,640))\n",
    "datasets[f.keys()[0]][101,:,:] = images[f.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "f.create_dataset(\"autochunk1\", state_log.shape, chunks=True,maxshape = (None,size),compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "f['autochunk1'][:,:] = state_log.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f['autochunk']\n",
    "a_shape = a.shape\n",
    "k = pd.DataFrame(np.random.rand(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "a.resize(2*a_shape[0],0)\n",
    "a[2*a_shape[0]:a_shape[0],:] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datetime.now()\n",
    "a.strftime(\"%Y_%M_%d_%H_%M_%S.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
